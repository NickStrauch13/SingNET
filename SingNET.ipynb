{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1d266c-7afa-43a4-a521-2aca2fa1bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e448b-d7ff-4e85-9c7b-7392e1eb4c28",
   "metadata": {},
   "source": [
    "##### Input size = [3, 385, 1085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cba515-561c-40f9-a519-103e3586ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x/(1+torch.exp(-x))\n",
    "\n",
    "# Custom 2d average pooling. Used directly prior to the fully connected layer(s)\n",
    "#\n",
    "# dims: Tuple representing the two dimensions to pool.\n",
    "# keep_dims: Boolean determining if output should preserve number of input dimensions.\n",
    "def avg_pool(x, dims, keep_dims=False):\n",
    "    summed_tensor = torch.sum(x, dim=dims)\n",
    "    if keep_dims:\n",
    "        reshaped_tensor = summed_tensor.unsqueeze(dim=dims[0]).unsqueeze(dim=dims[1])\n",
    "        return reshaped_tensor\n",
    "    return summed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a37aad-a821-40a8-b88f-1e12b31f0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNET arch\n",
    "class SingNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingNET, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer7_12 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(512, 5)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = self.layer14(out)\n",
    "        \n",
    "        out = avg_pool(out, (2,3))\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c854ab3-fb1a-4a79-b303-e6a8bc85c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"data/costa_rica/spectrogram/Broad-billed_Motmot/Broad-billed_Motmot_105_0.jpg\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img_tensor = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2d8d2b-517f-4f14-9d49-913562f8bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 385, 1085])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27251214-a651-4f54-82c6-1610e2d89a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5097, -3.3180, -0.3334, -2.7955,  4.9408]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SingNET()\n",
    "\n",
    "net.forward(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6446a09d-64bb-4949-a79d-852263086adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387589\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in net.parameters())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b23af5-e606-4284-bb0d-931478107b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b4ba99-0b04-4e1e-a26e-d1b6ef951e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epochs=100, batch_size=8, lr=0.005, L2_reg=0.01, saved_filepath=\"saved_models/test_model.pt\"):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device in use: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        #torch.cuda.max_memory_allocated(max_split_size_mb=1024)\n",
    "    net.to(device)\n",
    "    print(\"==> Starting Data Preparation...\")\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_set = ImageFolder(\"data/costa_rica/train\", transform=data_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_set = ImageFolder(\"data/costa_rica/validation\", transform=data_transform)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=L2_reg)\n",
    "    #scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5), int(epochs*0.75)], gamma=0.1)\n",
    "    best_acc = 0\n",
    "    \n",
    "    print(\"==> Training Initiated...\")\n",
    "    for epoch in range(0, epochs):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        print(f\"Train Loss: {round(train_loss,3)} | Train Acc: {round(correct/total,3)}\")\n",
    "        #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net.forward(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        val_acc = correct/total\n",
    "        \n",
    "        print(f\"Val Loss:   {round(val_loss,3)} | Val Acc:   {round(val_acc,3)}\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(\"Saving Model...\")\n",
    "            torch.save(net.state_dict(), saved_filepath)\n",
    "    \n",
    "    print(\"=========> Training Complete <=========\")\n",
    "    print(f\"Best Validation Accuracy: {best_acc}\")\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152a3fb0-0f2d-45ab-bc03-b4097bff2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "==> Starting Data Preparation...\n",
      "==> Training Initiated...\n",
      "Epoch 0/100\n",
      "Train Loss: 403.113 | Train Acc: 0.374\n",
      "Val Loss:   245.762 | Val Acc:   0.419\n",
      "Saving Model...\n",
      "Epoch 1/100\n",
      "Train Loss: 237.4 | Train Acc: 0.474\n",
      "Val Loss:   235.232 | Val Acc:   0.438\n",
      "Saving Model...\n",
      "Epoch 2/100\n",
      "Train Loss: 169.475 | Train Acc: 0.631\n",
      "Val Loss:   183.851 | Val Acc:   0.512\n",
      "Saving Model...\n",
      "Epoch 3/100\n",
      "Train Loss: 160.128 | Train Acc: 0.663\n",
      "Val Loss:   152.79 | Val Acc:   0.675\n",
      "Saving Model...\n",
      "Epoch 4/100\n",
      "Train Loss: 149.626 | Train Acc: 0.691\n",
      "Val Loss:   227.587 | Val Acc:   0.444\n",
      "Epoch 5/100\n",
      "Train Loss: 151.196 | Train Acc: 0.693\n",
      "Val Loss:   132.656 | Val Acc:   0.694\n",
      "Saving Model...\n",
      "Epoch 6/100\n",
      "Train Loss: 149.251 | Train Acc: 0.691\n",
      "Val Loss:   233.997 | Val Acc:   0.438\n",
      "Epoch 7/100\n",
      "Train Loss: 148.625 | Train Acc: 0.699\n",
      "Val Loss:   215.687 | Val Acc:   0.475\n",
      "Epoch 8/100\n",
      "Train Loss: 151.998 | Train Acc: 0.689\n",
      "Val Loss:   233.806 | Val Acc:   0.438\n",
      "Epoch 9/100\n",
      "Train Loss: 143.42 | Train Acc: 0.705\n",
      "Val Loss:   220.292 | Val Acc:   0.456\n",
      "Epoch 10/100\n",
      "Train Loss: 147.554 | Train Acc: 0.683\n",
      "Val Loss:   234.276 | Val Acc:   0.438\n",
      "Epoch 11/100\n",
      "Train Loss: 144.298 | Train Acc: 0.692\n",
      "Val Loss:   166.753 | Val Acc:   0.625\n",
      "Epoch 12/100\n",
      "Train Loss: 139.172 | Train Acc: 0.722\n",
      "Val Loss:   112.18 | Val Acc:   0.738\n",
      "Saving Model...\n",
      "Epoch 13/100\n",
      "Train Loss: 133.082 | Train Acc: 0.715\n",
      "Val Loss:   174.999 | Val Acc:   0.719\n",
      "Epoch 14/100\n",
      "Train Loss: 143.852 | Train Acc: 0.716\n",
      "Val Loss:   220.591 | Val Acc:   0.469\n",
      "Epoch 15/100\n",
      "Train Loss: 128.237 | Train Acc: 0.735\n",
      "Val Loss:   159.005 | Val Acc:   0.662\n",
      "Epoch 16/100\n",
      "Train Loss: 117.147 | Train Acc: 0.74\n",
      "Val Loss:   199.958 | Val Acc:   0.5\n",
      "Epoch 17/100\n",
      "Train Loss: 123.71 | Train Acc: 0.745\n",
      "Val Loss:   120.619 | Val Acc:   0.738\n",
      "Epoch 18/100\n",
      "Train Loss: 121.239 | Train Acc: 0.742\n",
      "Val Loss:   213.586 | Val Acc:   0.487\n",
      "Epoch 19/100\n",
      "Train Loss: 120.18 | Train Acc: 0.749\n",
      "Val Loss:   165.256 | Val Acc:   0.588\n",
      "Epoch 20/100\n",
      "Train Loss: 113.695 | Train Acc: 0.749\n",
      "Val Loss:   166.227 | Val Acc:   0.606\n",
      "Epoch 21/100\n",
      "Train Loss: 128.146 | Train Acc: 0.732\n",
      "Val Loss:   142.423 | Val Acc:   0.637\n",
      "Epoch 22/100\n",
      "Train Loss: 115.624 | Train Acc: 0.746\n",
      "Val Loss:   252.698 | Val Acc:   0.444\n",
      "Epoch 23/100\n",
      "Train Loss: 114.304 | Train Acc: 0.749\n",
      "Val Loss:   254.746 | Val Acc:   0.438\n",
      "Epoch 24/100\n",
      "Train Loss: 118.064 | Train Acc: 0.752\n",
      "Val Loss:   204.093 | Val Acc:   0.506\n",
      "Epoch 25/100\n",
      "Train Loss: 114.867 | Train Acc: 0.752\n",
      "Val Loss:   114.52 | Val Acc:   0.713\n",
      "Epoch 26/100\n",
      "Train Loss: 114.308 | Train Acc: 0.748\n",
      "Val Loss:   211.546 | Val Acc:   0.475\n",
      "Epoch 27/100\n",
      "Train Loss: 111.497 | Train Acc: 0.741\n",
      "Val Loss:   254.667 | Val Acc:   0.244\n",
      "Epoch 28/100\n",
      "Train Loss: 115.835 | Train Acc: 0.753\n",
      "Val Loss:   247.361 | Val Acc:   0.438\n",
      "Epoch 29/100\n",
      "Train Loss: 110.357 | Train Acc: 0.754\n",
      "Val Loss:   280.163 | Val Acc:   0.438\n",
      "Epoch 30/100\n",
      "Train Loss: 113.894 | Train Acc: 0.754\n",
      "Val Loss:   259.733 | Val Acc:   0.438\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m SingNET()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/reg_01.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, epochs, batch_size, lr, L2_reg, saved_filepath)\u001b[0m\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 40\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = SingNET()\n",
    "train(net, epochs=100, batch_size=8, lr=0.005, L2_reg=0.03, saved_filepath=\"saved_models/reg_03.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5957f-a5ab-4a47-8e7f-fd71dbfa729e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
