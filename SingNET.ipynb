{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1d266c-7afa-43a4-a521-2aca2fa1bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e448b-d7ff-4e85-9c7b-7392e1eb4c28",
   "metadata": {},
   "source": [
    "##### Input size = [3, 271, 781]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cba515-561c-40f9-a519-103e3586ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x/(1+torch.exp(-x))\n",
    "\n",
    "# Custom 2d average pooling. Used directly prior to the fully connected layer(s)\n",
    "#\n",
    "# dims: Tuple representing the two dimensions to pool.\n",
    "# keep_dims: Boolean determining if output should preserve number of input dimensions.\n",
    "def avg_pool(x, dims, keep_dims=False):\n",
    "    summed_tensor = torch.sum(x, dim=dims)\n",
    "    if keep_dims:\n",
    "        reshaped_tensor = summed_tensor.unsqueeze(dim=dims[0]).unsqueeze(dim=dims[1])\n",
    "        return reshaped_tensor\n",
    "    return summed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94a37aad-a821-40a8-b88f-1e12b31f0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNET arch\n",
    "class SingNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingNET, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer7_12 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(512, 5)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer7_12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = self.layer14(out)\n",
    "        \n",
    "        out = avg_pool(out, (2,3))\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c854ab3-fb1a-4a79-b303-e6a8bc85c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"data/costa_rica/train_dn/Yellow-throated_Toucan/Yellow-throated_Toucan_146_0dn.jpg\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img_tensor = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c2d8d2b-517f-4f14-9d49-913562f8bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 271, 781])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27251214-a651-4f54-82c6-1610e2d89a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 3, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2369, 38.8524,  1.7380,  1.2628, 22.6226]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SingNET()\n",
    "\n",
    "net.forward(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6446a09d-64bb-4949-a79d-852263086adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387589\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in net.parameters())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b23af5-e606-4284-bb0d-931478107b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19b4ba99-0b04-4e1e-a26e-d1b6ef951e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epochs=100, batch_size=8, lr=0.005, L2_reg=0.01, saved_filepath=\"saved_models/test_model.pt\"):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device in use: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        #torch.cuda.max_memory_allocated(max_split_size_mb=1024)\n",
    "    net.to(device)\n",
    "    print(\"==> Starting Data Preparation...\")\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_set = ImageFolder(\"data/costa_rica/train\", transform=data_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_set = ImageFolder(\"data/costa_rica/validation\", transform=data_transform)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=L2_reg)\n",
    "    #scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5), int(epochs*0.75)], gamma=0.1)\n",
    "    best_acc = 0\n",
    "    \n",
    "    print(\"==> Training Initiated...\")\n",
    "    for epoch in range(0, epochs):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        print(f\"Train Loss: {round(train_loss,3)} | Train Acc: {round(correct/total,3)}\")\n",
    "        #scheduler.step()\n",
    "        \n",
    "        net.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net.forward(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        val_acc = correct/total\n",
    "        \n",
    "        print(f\"Val Loss:   {round(val_loss,3)} | Val Acc:   {round(val_acc,3)}\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(\"Saving Model...\")\n",
    "            torch.save(net.state_dict(), saved_filepath)\n",
    "    \n",
    "    print(\"=========> Training Complete <=========\")\n",
    "    print(f\"Best Validation Accuracy: {best_acc}\")\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "152a3fb0-0f2d-45ab-bc03-b4097bff2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "==> Starting Data Preparation...\n",
      "==> Training Initiated...\n",
      "Epoch 0/100\n",
      "Train Loss: 1038.337 | Train Acc: 0.414\n",
      "Val Loss:   373.306 | Val Acc:   0.481\n",
      "Saving Model...\n",
      "Epoch 1/100\n",
      "Train Loss: 430.989 | Train Acc: 0.518\n",
      "Val Loss:   416.491 | Val Acc:   0.475\n",
      "Epoch 2/100\n",
      "Train Loss: 283.709 | Train Acc: 0.536\n",
      "Val Loss:   219.16 | Val Acc:   0.463\n",
      "Epoch 3/100\n",
      "Train Loss: 206.582 | Train Acc: 0.592\n",
      "Val Loss:   177.366 | Val Acc:   0.569\n",
      "Saving Model...\n",
      "Epoch 4/100\n",
      "Train Loss: 178.44 | Train Acc: 0.657\n",
      "Val Loss:   255.481 | Val Acc:   0.619\n",
      "Saving Model...\n",
      "Epoch 5/100\n",
      "Train Loss: 161.45 | Train Acc: 0.696\n",
      "Val Loss:   160.586 | Val Acc:   0.562\n",
      "Epoch 6/100\n",
      "Train Loss: 177.501 | Train Acc: 0.656\n",
      "Val Loss:   158.193 | Val Acc:   0.688\n",
      "Saving Model...\n",
      "Epoch 7/100\n",
      "Train Loss: 163.371 | Train Acc: 0.677\n",
      "Val Loss:   175.733 | Val Acc:   0.65\n",
      "Epoch 8/100\n",
      "Train Loss: 153.917 | Train Acc: 0.705\n",
      "Val Loss:   142.373 | Val Acc:   0.738\n",
      "Saving Model...\n",
      "Epoch 9/100\n",
      "Train Loss: 150.089 | Train Acc: 0.706\n",
      "Val Loss:   220.499 | Val Acc:   0.463\n",
      "Epoch 10/100\n",
      "Train Loss: 149.609 | Train Acc: 0.709\n",
      "Val Loss:   207.567 | Val Acc:   0.463\n",
      "Epoch 11/100\n",
      "Train Loss: 146.541 | Train Acc: 0.722\n",
      "Val Loss:   129.584 | Val Acc:   0.706\n",
      "Epoch 12/100\n",
      "Train Loss: 139.721 | Train Acc: 0.723\n",
      "Val Loss:   144.918 | Val Acc:   0.606\n",
      "Epoch 13/100\n",
      "Train Loss: 145.302 | Train Acc: 0.713\n",
      "Val Loss:   250.328 | Val Acc:   0.481\n",
      "Epoch 14/100\n",
      "Train Loss: 134.002 | Train Acc: 0.73\n",
      "Val Loss:   116.772 | Val Acc:   0.762\n",
      "Saving Model...\n",
      "Epoch 15/100\n",
      "Train Loss: 140.776 | Train Acc: 0.706\n",
      "Val Loss:   143.305 | Val Acc:   0.588\n",
      "Epoch 16/100\n",
      "Train Loss: 136.652 | Train Acc: 0.717\n",
      "Val Loss:   231.634 | Val Acc:   0.581\n",
      "Epoch 17/100\n",
      "Train Loss: 139.145 | Train Acc: 0.717\n",
      "Val Loss:   152.95 | Val Acc:   0.656\n",
      "Epoch 18/100\n",
      "Train Loss: 134.516 | Train Acc: 0.734\n",
      "Val Loss:   154.763 | Val Acc:   0.569\n",
      "Epoch 19/100\n",
      "Train Loss: 128.591 | Train Acc: 0.737\n",
      "Val Loss:   163.938 | Val Acc:   0.594\n",
      "Epoch 20/100\n",
      "Train Loss: 131.126 | Train Acc: 0.727\n",
      "Val Loss:   239.199 | Val Acc:   0.444\n",
      "Epoch 21/100\n",
      "Train Loss: 129.325 | Train Acc: 0.736\n",
      "Val Loss:   141.969 | Val Acc:   0.65\n",
      "Epoch 22/100\n",
      "Train Loss: 131.021 | Train Acc: 0.715\n",
      "Val Loss:   176.549 | Val Acc:   0.55\n",
      "Epoch 23/100\n",
      "Train Loss: 129.227 | Train Acc: 0.728\n",
      "Val Loss:   249.922 | Val Acc:   0.412\n",
      "Epoch 24/100\n",
      "Train Loss: 128.558 | Train Acc: 0.747\n",
      "Val Loss:   262.521 | Val Acc:   0.181\n",
      "Epoch 25/100\n",
      "Train Loss: 123.065 | Train Acc: 0.75\n",
      "Val Loss:   251.126 | Val Acc:   0.163\n",
      "Epoch 26/100\n",
      "Train Loss: 114.588 | Train Acc: 0.759\n",
      "Val Loss:   276.749 | Val Acc:   0.169\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m SingNET()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL2_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/reg_03_dn.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, epochs, batch_size, lr, L2_reg, saved_filepath)\u001b[0m\n\u001b[0;32m     30\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 33\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     35\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mforward(inputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = SingNET()\n",
    "train(net, epochs=100, batch_size=8, lr=0.005, L2_reg=0.03, saved_filepath=\"saved_models/reg_03_dn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5957f-a5ab-4a47-8e7f-fd71dbfa729e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
