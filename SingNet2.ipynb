{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20df4c4-347b-47cf-b475-6bcbfc1c079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from PreprocessingFunctions import *\n",
    "from ModelEval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3d9794-ce10-43c4-8544-b79fee874058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                         std=[0.229, 0.224, 0.225])])\n",
    "# train_set = ImageFolder(\"data/small_train_172\", transform=data_transform)\n",
    "# train_loader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=1)\n",
    "# val_set = ImageFolder(\"data/small_validation_172\", transform=data_transform)\n",
    "# val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "# class_stats = compute_class_stats(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a188d01d-0d7e-419c-9314-c1448aa77093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_stats = (172, 37389, [269, 63, 500, 290, 111, 238, 500, 111, 324, 111, 46, 500, 38, 83, 46, 396, 246, 500,\n",
    "                            167, 51, 92, 54, 180, 97, 195, 60, 222, 81, 41, 277, 315, 348, 86, 219, 67, 45, 209,\n",
    "                            61, 135, 195, 44, 500, 351, 500, 453, 500, 500, 332, 332, 68, 189, 83, 77, 396, 242,\n",
    "                            255, 50, 326, 500, 116, 500, 500, 234, 34, 38, 114, 278, 90, 500, 187, 47, 208, 58,\n",
    "                            500, 279, 500, 172, 207, 500, 99, 207, 63, 500, 55, 113, 432, 339, 34, 168, 36, 86,\n",
    "                            50, 257, 500, 179, 209, 98, 42, 87, 65, 41, 83, 112, 261, 500, 394, 142, 147, 156,\n",
    "                            84, 500, 256, 71, 59, 270, 264, 467, 73, 153, 58, 132, 201, 131, 69, 74, 43, 230,\n",
    "                            108, 500, 75, 218, 343, 58, 167, 239, 216, 99, 500, 202, 141, 72, 87, 500, 140, 70,\n",
    "                            72, 463, 91, 138, 213, 126, 80, 97, 500, 280, 42, 53, 500, 51, 500, 93, 145, 264,\n",
    "                            500, 495, 281, 500, 87, 307, 201, 156, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d6162b-28bc-43ae-b28b-ef4ce3be22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "#model = models.mobilenet_v2()\n",
    "\n",
    "model.classifier[1] = nn.Linear(1280, 172)\n",
    "#model.load_state_dict(torch.load(\"saved_models/ft_mobile_5.pt\"))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e5bd1e-b405-494c-9d1d-d2aa2fdd6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model, train_stats, epochs=10, batch_size=16, lr=0.001, L2_reg=0.01, \n",
    "             train_path=\"data/small_train_sifted\", val_path=\"data/small_validation_sifted\", \n",
    "             saved_filepath=\"saved_models/fine-tuned_model.pt\"):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device in use: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        #torch.cuda.max_memory_allocated(max_split_size_mb=1024)\n",
    "    model.to(device)\n",
    "    print(\"==> Starting Data Preparation...\")\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_set = ImageFolder(train_path, transform=data_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    val_set = ImageFolder(val_path, transform=data_transform)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "    \n",
    "    num_classes, total_samples, class_samples = train_stats\n",
    "    weights = torch.FloatTensor([total_samples / (num_classes * s) for s in class_samples]).to(device)\n",
    "    loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=L2_reg)\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    print(\"==> Training Initiated...\")\n",
    "    for epoch in range(0, epochs):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        print(f\"Train Loss: {round(train_loss,3)} | Train Acc: {round(correct/total,3)}\")\n",
    "        #scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model.forward(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        val_acc = correct/total\n",
    "        \n",
    "        print(f\"Val Loss:   {round(val_loss,3)} | Val Acc:   {round(val_acc,3)}\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(\"Saving Model...\")\n",
    "            torch.save(model.state_dict(), saved_filepath)\n",
    "    \n",
    "    print(\"=========> Training Complete <=========\")\n",
    "    print(f\"Best Validation Accuracy: {best_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4fe16-9918-4f4b-a4ee-fd8900994b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "==> Starting Data Preparation...\n",
      "==> Training Initiated...\n",
      "Epoch 0/100\n",
      "Train Loss: 17107.441 | Train Acc: 0.249\n",
      "Val Loss:   30139.9 | Val Acc:   0.004\n",
      "Saving Model...\n",
      "Epoch 1/100\n",
      "Train Loss: 10983.393 | Train Acc: 0.471\n",
      "Val Loss:   34688.599 | Val Acc:   0.005\n",
      "Saving Model...\n",
      "Epoch 2/100\n",
      "Train Loss: 9255.029 | Train Acc: 0.547\n",
      "Val Loss:   34908.639 | Val Acc:   0.006\n",
      "Saving Model...\n",
      "Epoch 3/100\n"
     ]
    }
   ],
   "source": [
    "finetune(model, class_stats, epochs=100, batch_size=8, lr=0.0003, L2_reg=0.001,\n",
    "         train_path=\"data/small_train_172\", val_path = \"data/small_validation_172\",\n",
    "         saved_filepath=\"saved_models/ft_mobile172_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d61993-adfd-4e47-aaec-d53a007b0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 3892/4824 ===> 80.67993366500829%\n",
      "Top 3 accuracy: 4317/4824 ===> 89.49004975124379%\n",
      "Top 5 accuracy: 4440/4824 ===> 92.03980099502488%\n",
      "Top 10 accuracy: 4566/4824 ==> 94.65174129353234%\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])])\n",
    "val_set = ImageFolder(\"data/small_validation_sifted\", transform=data_transform)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "model = models.mobilenet_v2()\n",
    "model.classifier[1] = nn.Linear(1280, 132)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/ft_mobile_6.pt\"))\n",
    "\n",
    "#generate_confusion_matrix(model, val_loader, \"data/small_train_sifted\")\n",
    "test_model(model, val_loader, top3top5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6601bf9-88b7-45da-8c10-01513a3d5598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
